{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"data/train/images/246-ktp_jpg.rf.fa9bf940931b0387b060f828f5ba6f8e.jpg\"\n",
    "\n",
    "# Convert image to RGB\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doctr.models import ocr_predictor\n",
    "from doctr.io import DocumentFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "model = ocr_predictor(det_arch='fast_small',reco_arch='crnn_mobilenet_v3_small',pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img_doc = DocumentFile.from_images(image_path)\n",
    "result = model(single_img_doc)\n",
    "export = result.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'geometry': ((np.float64(0.2802734375), np.float64(0.1201171875)),\n",
       "   (np.float64(0.7451171875), np.float64(0.158203125))),\n",
       "  'objectness_score': 0.8357551097869873,\n",
       "  'words': [{'value': 'PROVINSI',\n",
       "    'confidence': 0.485123872756958,\n",
       "    'geometry': ((np.float64(0.2802734375), np.float64(0.1201171875)),\n",
       "     (np.float64(0.4248046875), np.float64(0.1533203125))),\n",
       "    'objectness_score': 0.8792369365692139,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'SULAWESI',\n",
       "    'confidence': 0.8202192783355713,\n",
       "    'geometry': ((np.float64(0.4345703125), np.float64(0.1220703125)),\n",
       "     (np.float64(0.5947265625), np.float64(0.1552734375))),\n",
       "    'objectness_score': 0.822883665561676,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'SELATAN',\n",
       "    'confidence': 0.9891034960746765,\n",
       "    'geometry': ((np.float64(0.6015625), np.float64(0.1240234375)),\n",
       "     (np.float64(0.7451171875), np.float64(0.158203125))),\n",
       "    'objectness_score': 0.805144727230072,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.3583984375), np.float64(0.1640625)),\n",
       "   (np.float64(0.6669921875), np.float64(0.19921875))),\n",
       "  'objectness_score': 0.8366013765335083,\n",
       "  'words': [{'value': 'KABUPATEN',\n",
       "    'confidence': 0.9833657145500183,\n",
       "    'geometry': ((np.float64(0.3583984375), np.float64(0.1640625)),\n",
       "     (np.float64(0.54296875), np.float64(0.197265625))),\n",
       "    'objectness_score': 0.8234561681747437,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'MAROS',\n",
       "    'confidence': 0.9994794130325317,\n",
       "    'geometry': ((np.float64(0.5537109375), np.float64(0.1650390625)),\n",
       "     (np.float64(0.6669921875), np.float64(0.19921875))),\n",
       "    'objectness_score': 0.849746584892273,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0556640625), np.float64(0.220703125)),\n",
       "   (np.float64(0.1318359375), np.float64(0.2626953125))),\n",
       "  'objectness_score': 0.8816566467285156,\n",
       "  'words': [{'value': 'NIK',\n",
       "    'confidence': 0.9949601888656616,\n",
       "    'geometry': ((np.float64(0.0556640625), np.float64(0.220703125)),\n",
       "     (np.float64(0.1318359375), np.float64(0.2626953125))),\n",
       "    'objectness_score': 0.8816566467285156,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.224609375), np.float64(0.224609375)),\n",
       "   (np.float64(0.6650390625), np.float64(0.265625))),\n",
       "  'objectness_score': 0.7214372754096985,\n",
       "  'words': [{'value': ':',\n",
       "    'confidence': 0.9031318426132202,\n",
       "    'geometry': ((np.float64(0.224609375), np.float64(0.2275390625)),\n",
       "     (np.float64(0.2451171875), np.float64(0.2568359375))),\n",
       "    'objectness_score': 0.7357074022293091,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '7301032705130004',\n",
       "    'confidence': 0.2050483673810959,\n",
       "    'geometry': ((np.float64(0.2666015625), np.float64(0.224609375)),\n",
       "     (np.float64(0.6650390625), np.float64(0.265625))),\n",
       "    'objectness_score': 0.7071671485900879,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.056640625), np.float64(0.2978515625)),\n",
       "   (np.float64(0.12890625), np.float64(0.3310546875))),\n",
       "  'objectness_score': 0.8611822724342346,\n",
       "  'words': [{'value': 'Nama',\n",
       "    'confidence': 0.9997521042823792,\n",
       "    'geometry': ((np.float64(0.056640625), np.float64(0.2978515625)),\n",
       "     (np.float64(0.12890625), np.float64(0.3310546875))),\n",
       "    'objectness_score': 0.8611822724342346,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.2783203125), np.float64(0.2978515625)),\n",
       "   (np.float64(0.5712890625), np.float64(0.3310546875))),\n",
       "  'objectness_score': 0.872337539990743,\n",
       "  'words': [{'value': 'MUH',\n",
       "    'confidence': 0.9974207878112793,\n",
       "    'geometry': ((np.float64(0.2783203125), np.float64(0.2978515625)),\n",
       "     (np.float64(0.3466796875), np.float64(0.330078125))),\n",
       "    'objectness_score': 0.8708446025848389,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'DHIAUR',\n",
       "    'confidence': 0.9899669885635376,\n",
       "    'geometry': ((np.float64(0.3486328125), np.float64(0.2998046875)),\n",
       "     (np.float64(0.451171875), np.float64(0.330078125))),\n",
       "    'objectness_score': 0.8864884972572327,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'RAHMAN',\n",
       "    'confidence': 0.6727311611175537,\n",
       "    'geometry': ((np.float64(0.4560546875), np.float64(0.3017578125)),\n",
       "     (np.float64(0.5712890625), np.float64(0.3310546875))),\n",
       "    'objectness_score': 0.8596795201301575,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.05859375), np.float64(0.333984375)),\n",
       "   (np.float64(0.529296875), np.float64(0.369140625))),\n",
       "  'objectness_score': 0.7636976327214923,\n",
       "  'words': [{'value': 'Tampat/Tgl',\n",
       "    'confidence': 0.415814608335495,\n",
       "    'geometry': ((np.float64(0.05859375), np.float64(0.333984375)),\n",
       "     (np.float64(0.189453125), np.float64(0.369140625))),\n",
       "    'objectness_score': 0.8070476055145264,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'Lahir',\n",
       "    'confidence': 0.517527163028717,\n",
       "    'geometry': ((np.float64(0.1943359375), np.float64(0.333984375)),\n",
       "     (np.float64(0.2578125), np.float64(0.3662109375))),\n",
       "    'objectness_score': 0.7910131216049194,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '.',\n",
       "    'confidence': 0.9284809827804565,\n",
       "    'geometry': ((np.float64(0.26953125), np.float64(0.3544921875)),\n",
       "     (np.float64(0.275390625), np.float64(0.361328125))),\n",
       "    'objectness_score': 0.6196231842041016,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'MAROS,',\n",
       "    'confidence': 0.8647364974021912,\n",
       "    'geometry': ((np.float64(0.283203125), np.float64(0.3349609375)),\n",
       "     (np.float64(0.3837890625), np.float64(0.3662109375))),\n",
       "    'objectness_score': 0.8095960021018982,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '27-05',\n",
       "    'confidence': 0.9951565861701965,\n",
       "    'geometry': ((np.float64(0.3916015625), np.float64(0.3349609375)),\n",
       "     (np.float64(0.462890625), np.float64(0.3662109375))),\n",
       "    'objectness_score': 0.8478992581367493,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'a',\n",
       "    'confidence': 0.8967225551605225,\n",
       "    'geometry': ((np.float64(0.458984375), np.float64(0.34375)),\n",
       "     (np.float64(0.4716796875), np.float64(0.357421875))),\n",
       "    'objectness_score': 0.6585400104522705,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '1993',\n",
       "    'confidence': 0.9790369868278503,\n",
       "    'geometry': ((np.float64(0.46875), np.float64(0.3349609375)),\n",
       "     (np.float64(0.529296875), np.float64(0.3671875))),\n",
       "    'objectness_score': 0.8121642470359802,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0576171875), np.float64(0.3701171875)),\n",
       "   (np.float64(0.21875), np.float64(0.4013671875))),\n",
       "  'objectness_score': 0.8364766836166382,\n",
       "  'words': [{'value': 'Jenis',\n",
       "    'confidence': 0.977652370929718,\n",
       "    'geometry': ((np.float64(0.0576171875), np.float64(0.3701171875)),\n",
       "     (np.float64(0.12109375), np.float64(0.3994140625))),\n",
       "    'objectness_score': 0.8437501192092896,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'kelamin',\n",
       "    'confidence': 0.9863157868385315,\n",
       "    'geometry': ((np.float64(0.125), np.float64(0.37109375)),\n",
       "     (np.float64(0.21875), np.float64(0.4013671875))),\n",
       "    'objectness_score': 0.8292032480239868,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.279296875), np.float64(0.37109375)),\n",
       "   (np.float64(0.404296875), np.float64(0.400390625))),\n",
       "  'objectness_score': 0.840225338935852,\n",
       "  'words': [{'value': 'LAK-LAKI',\n",
       "    'confidence': 0.48963356018066406,\n",
       "    'geometry': ((np.float64(0.279296875), np.float64(0.37109375)),\n",
       "     (np.float64(0.404296875), np.float64(0.400390625))),\n",
       "    'objectness_score': 0.840225338935852,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.494140625), np.float64(0.3720703125)),\n",
       "   (np.float64(0.6572265625), np.float64(0.4033203125))),\n",
       "  'objectness_score': 0.8429588079452515,\n",
       "  'words': [{'value': 'Gol:',\n",
       "    'confidence': 0.3996318578720093,\n",
       "    'geometry': ((np.float64(0.494140625), np.float64(0.3720703125)),\n",
       "     (np.float64(0.5439453125), np.float64(0.4033203125))),\n",
       "    'objectness_score': 0.8457456827163696,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'Darah:B',\n",
       "    'confidence': 0.9019603729248047,\n",
       "    'geometry': ((np.float64(0.5517578125), np.float64(0.373046875)),\n",
       "     (np.float64(0.6572265625), np.float64(0.4033203125))),\n",
       "    'objectness_score': 0.8401719331741333,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0556640625), np.float64(0.40625)),\n",
       "   (np.float64(0.14453125), np.float64(0.4365234375))),\n",
       "  'objectness_score': 0.811427652835846,\n",
       "  'words': [{'value': 'Alamat',\n",
       "    'confidence': 0.9913175106048584,\n",
       "    'geometry': ((np.float64(0.0556640625), np.float64(0.40625)),\n",
       "     (np.float64(0.14453125), np.float64(0.4365234375))),\n",
       "    'objectness_score': 0.811427652835846,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.2802734375), np.float64(0.404296875)),\n",
       "   (np.float64(0.5634765625), np.float64(0.4375))),\n",
       "  'objectness_score': 0.8465747634569804,\n",
       "  'words': [{'value': 'PP',\n",
       "    'confidence': 0.9978870153427124,\n",
       "    'geometry': ((np.float64(0.2802734375), np.float64(0.404296875)),\n",
       "     (np.float64(0.3193359375), np.float64(0.4375))),\n",
       "    'objectness_score': 0.8237287402153015,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'DARUL',\n",
       "    'confidence': 0.9948311448097229,\n",
       "    'geometry': ((np.float64(0.3251953125), np.float64(0.4072265625)),\n",
       "     (np.float64(0.4111328125), np.float64(0.4375))),\n",
       "    'objectness_score': 0.8635474443435669,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'ISTIQAMAH',\n",
       "    'confidence': 0.9670712947845459,\n",
       "    'geometry': ((np.float64(0.4189453125), np.float64(0.41015625)),\n",
       "     (np.float64(0.5634765625), np.float64(0.4365234375))),\n",
       "    'objectness_score': 0.8524481058120728,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.109375), np.float64(0.44140625)),\n",
       "   (np.float64(0.201171875), np.float64(0.4716796875))),\n",
       "  'objectness_score': 0.8552296161651611,\n",
       "  'words': [{'value': 'RT/RW',\n",
       "    'confidence': 0.9581121802330017,\n",
       "    'geometry': ((np.float64(0.109375), np.float64(0.44140625)),\n",
       "     (np.float64(0.201171875), np.float64(0.4716796875))),\n",
       "    'objectness_score': 0.8552296161651611,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.2822265625), np.float64(0.4443359375)),\n",
       "   (np.float64(0.3759765625), np.float64(0.4716796875))),\n",
       "  'objectness_score': 0.901395320892334,\n",
       "  'words': [{'value': '001/002',\n",
       "    'confidence': 0.7949333786964417,\n",
       "    'geometry': ((np.float64(0.2822265625), np.float64(0.4443359375)),\n",
       "     (np.float64(0.3759765625), np.float64(0.4716796875))),\n",
       "    'objectness_score': 0.901395320892334,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.109375), np.float64(0.478515625)),\n",
       "   (np.float64(0.2197265625), np.float64(0.5087890625))),\n",
       "  'objectness_score': 0.8198512196540833,\n",
       "  'words': [{'value': 'Kel/Desa',\n",
       "    'confidence': 0.5617420077323914,\n",
       "    'geometry': ((np.float64(0.109375), np.float64(0.478515625)),\n",
       "     (np.float64(0.2197265625), np.float64(0.5087890625))),\n",
       "    'objectness_score': 0.8198512196540833,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.2822265625), np.float64(0.4794921875)),\n",
       "   (np.float64(0.3935546875), np.float64(0.5087890625))),\n",
       "  'objectness_score': 0.8638628125190735,\n",
       "  'words': [{'value': 'BONTOA',\n",
       "    'confidence': 0.997539222240448,\n",
       "    'geometry': ((np.float64(0.2822265625), np.float64(0.4794921875)),\n",
       "     (np.float64(0.3935546875), np.float64(0.5087890625))),\n",
       "    'objectness_score': 0.8638628125190735,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.111328125), np.float64(0.5166015625)),\n",
       "   (np.float64(0.2412109375), np.float64(0.54296875))),\n",
       "  'objectness_score': 0.8415281176567078,\n",
       "  'words': [{'value': 'Kecamatan',\n",
       "    'confidence': 0.9868582487106323,\n",
       "    'geometry': ((np.float64(0.111328125), np.float64(0.5166015625)),\n",
       "     (np.float64(0.2412109375), np.float64(0.54296875))),\n",
       "    'objectness_score': 0.8415281176567078,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.283203125), np.float64(0.5166015625)),\n",
       "   (np.float64(0.3837890625), np.float64(0.5439453125))),\n",
       "  'objectness_score': 0.8826640844345093,\n",
       "  'words': [{'value': 'MANDAI',\n",
       "    'confidence': 0.9723880887031555,\n",
       "    'geometry': ((np.float64(0.283203125), np.float64(0.5166015625)),\n",
       "     (np.float64(0.3837890625), np.float64(0.5439453125))),\n",
       "    'objectness_score': 0.8826640844345093,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.052734375), np.float64(0.55078125)),\n",
       "   (np.float64(0.138671875), np.float64(0.5869140625))),\n",
       "  'objectness_score': 0.7602846026420593,\n",
       "  'words': [{'value': 'Agama',\n",
       "    'confidence': 0.9981163740158081,\n",
       "    'geometry': ((np.float64(0.052734375), np.float64(0.55078125)),\n",
       "     (np.float64(0.138671875), np.float64(0.5869140625))),\n",
       "    'objectness_score': 0.7602846026420593,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.275390625), np.float64(0.55078125)),\n",
       "   (np.float64(0.361328125), np.float64(0.58203125))),\n",
       "  'objectness_score': 0.8089154362678528,\n",
       "  'words': [{'value': 'ISLAM',\n",
       "    'confidence': 0.9966477155685425,\n",
       "    'geometry': ((np.float64(0.275390625), np.float64(0.55078125)),\n",
       "     (np.float64(0.361328125), np.float64(0.58203125))),\n",
       "    'objectness_score': 0.8089154362678528,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0537109375), np.float64(0.5849609375)),\n",
       "   (np.float64(0.4619140625), np.float64(0.6162109375))),\n",
       "  'objectness_score': 0.8389762789011002,\n",
       "  'words': [{'value': 'Status',\n",
       "    'confidence': 0.9972229599952698,\n",
       "    'geometry': ((np.float64(0.0537109375), np.float64(0.5849609375)),\n",
       "     (np.float64(0.12890625), np.float64(0.6162109375))),\n",
       "    'objectness_score': 0.8470548391342163,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'Perkawinan:',\n",
       "    'confidence': 0.4247622787952423,\n",
       "    'geometry': ((np.float64(0.1357421875), np.float64(0.5869140625)),\n",
       "     (np.float64(0.2734375), np.float64(0.6162109375))),\n",
       "    'objectness_score': 0.7802794575691223,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'BELUM',\n",
       "    'confidence': 0.9815321564674377,\n",
       "    'geometry': ((np.float64(0.283203125), np.float64(0.587890625)),\n",
       "     (np.float64(0.3720703125), np.float64(0.615234375))),\n",
       "    'objectness_score': 0.8496220111846924,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'KAWIN',\n",
       "    'confidence': 0.8669403791427612,\n",
       "    'geometry': ((np.float64(0.3798828125), np.float64(0.5888671875)),\n",
       "     (np.float64(0.4619140625), np.float64(0.6162109375))),\n",
       "    'objectness_score': 0.8789488077163696,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0537109375), np.float64(0.623046875)),\n",
       "   (np.float64(0.1708984375), np.float64(0.6572265625))),\n",
       "  'objectness_score': 0.822176456451416,\n",
       "  'words': [{'value': 'Pekerjaan',\n",
       "    'confidence': 0.9338170289993286,\n",
       "    'geometry': ((np.float64(0.0537109375), np.float64(0.623046875)),\n",
       "     (np.float64(0.1708984375), np.float64(0.6572265625))),\n",
       "    'objectness_score': 0.822176456451416,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.2841796875), np.float64(0.625)),\n",
       "   (np.float64(0.5615234375), np.float64(0.6533203125))),\n",
       "  'objectness_score': 0.7768116593360901,\n",
       "  'words': [{'value': 'PELAJAPMAHASISWA',\n",
       "    'confidence': 0.01145857386291027,\n",
       "    'geometry': ((np.float64(0.2841796875), np.float64(0.625)),\n",
       "     (np.float64(0.5615234375), np.float64(0.6533203125))),\n",
       "    'objectness_score': 0.7768116593360901,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.7802734375), np.float64(0.6396484375)),\n",
       "   (np.float64(0.8642578125), np.float64(0.6669921875))),\n",
       "  'objectness_score': 0.7639692425727844,\n",
       "  'words': [{'value': 'MAROS',\n",
       "    'confidence': 0.9992554783821106,\n",
       "    'geometry': ((np.float64(0.7802734375), np.float64(0.6396484375)),\n",
       "     (np.float64(0.8642578125), np.float64(0.6669921875))),\n",
       "    'objectness_score': 0.7639692425727844,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0546875), np.float64(0.66015625)),\n",
       "   (np.float64(0.3349609375), np.float64(0.693359375))),\n",
       "  'objectness_score': 0.7003967016935349,\n",
       "  'words': [{'value': 'Kewarganegeraan',\n",
       "    'confidence': 0.617887020111084,\n",
       "    'geometry': ((np.float64(0.0546875), np.float64(0.66015625)),\n",
       "     (np.float64(0.267578125), np.float64(0.693359375))),\n",
       "    'objectness_score': 0.7597393989562988,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '*',\n",
       "    'confidence': 0.3950871229171753,\n",
       "    'geometry': ((np.float64(0.2666015625), np.float64(0.67578125)),\n",
       "     (np.float64(0.2763671875), np.float64(0.689453125))),\n",
       "    'objectness_score': 0.5700234770774841,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'a',\n",
       "    'confidence': 0.5307886600494385,\n",
       "    'geometry': ((np.float64(0.267578125), np.float64(0.6669921875)),\n",
       "     (np.float64(0.2744140625), np.float64(0.6787109375))),\n",
       "    'objectness_score': 0.6426098346710205,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'WNI',\n",
       "    'confidence': 0.9988200664520264,\n",
       "    'geometry': ((np.float64(0.28125), np.float64(0.66015625)),\n",
       "     (np.float64(0.3349609375), np.float64(0.6904296875))),\n",
       "    'objectness_score': 0.8292140960693359,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.7666015625), np.float64(0.6689453125)),\n",
       "   (np.float64(0.880859375), np.float64(0.6982421875))),\n",
       "  'objectness_score': 0.7770394086837769,\n",
       "  'words': [{'value': '17-10-2017',\n",
       "    'confidence': 0.6512308120727539,\n",
       "    'geometry': ((np.float64(0.7666015625), np.float64(0.6689453125)),\n",
       "     (np.float64(0.880859375), np.float64(0.6982421875))),\n",
       "    'objectness_score': 0.7770394086837769,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]},\n",
       " {'geometry': ((np.float64(0.0537109375), np.float64(0.693359375)),\n",
       "   (np.float64(0.484375), np.float64(0.7314453125))),\n",
       "  'objectness_score': 0.8036879181861878,\n",
       "  'words': [{'value': 'Berlaku',\n",
       "    'confidence': 0.6375102996826172,\n",
       "    'geometry': ((np.float64(0.0537109375), np.float64(0.693359375)),\n",
       "     (np.float64(0.1435546875), np.float64(0.724609375))),\n",
       "    'objectness_score': 0.8586359620094299,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'Hingga',\n",
       "    'confidence': 0.5578166246414185,\n",
       "    'geometry': ((np.float64(0.1484375), np.float64(0.6953125)),\n",
       "     (np.float64(0.232421875), np.float64(0.7314453125))),\n",
       "    'objectness_score': 0.8238428831100464,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': '',\n",
       "    'confidence': 0.25373575091362,\n",
       "    'geometry': ((np.float64(0.2626953125), np.float64(0.7109375)),\n",
       "     (np.float64(0.2763671875), np.float64(0.7255859375))),\n",
       "    'objectness_score': 0.6688697338104248,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'SEUMUR',\n",
       "    'confidence': 0.9196938276290894,\n",
       "    'geometry': ((np.float64(0.2822265625), np.float64(0.6953125)),\n",
       "     (np.float64(0.39453125), np.float64(0.7255859375))),\n",
       "    'objectness_score': 0.8076848983764648,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}},\n",
       "   {'value': 'HIDUP',\n",
       "    'confidence': 0.5005283951759338,\n",
       "    'geometry': ((np.float64(0.400390625), np.float64(0.6962890625)),\n",
       "     (np.float64(0.484375), np.float64(0.7265625))),\n",
       "    'objectness_score': 0.8594061136245728,\n",
       "    'crop_orientation': {'value': 0, 'confidence': None}}]}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export['pages'][0][\"blocks\"][0][\"lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136553850559851"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_objectness_scores(blocks):\n",
    "    scores = []\n",
    "    for block in blocks:\n",
    "        scores.append(block.get('objectness_score', 0))\n",
    "        if 'lines' in block:\n",
    "            for line in block['lines']:\n",
    "                scores.append(line.get('objectness_score', 0))\n",
    "                if 'words' in line:\n",
    "                    for word in line['words']:\n",
    "                        scores.append(word.get('objectness_score', 0))\n",
    "        if 'words' in block:\n",
    "            for word in block['words']:\n",
    "                scores.append(word.get('objectness_score', 0))\n",
    "    return scores\n",
    "\n",
    "# Extract scores\n",
    "scores = extract_objectness_scores(export['pages'][0]['blocks'])\n",
    "\n",
    "# Calculate average\n",
    "average_score = sum(scores) / len(scores) if scores else 0\n",
    "average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRTextProcessor:\n",
    "    def __init__(self, tolerance=15):\n",
    "        self.tolerance = tolerance\n",
    "    \n",
    "    def process_ocr_result(self, result):\n",
    "        \"\"\"Process OCR result and return corrected text alignments.\"\"\"\n",
    "        # Extract all words with their coordinates and text\n",
    "        words = []\n",
    "        for page in result['pages']:\n",
    "            for block in page['blocks']:\n",
    "                for line in block.get('lines', []):\n",
    "                    for word in line.get('words', []):\n",
    "                        # Get coordinates from geometry\n",
    "                        coords = word['geometry']\n",
    "                        # Convert coordinates to more readable format\n",
    "                        x1, y1 = coords[0]\n",
    "                        x2, y2 = coords[1]\n",
    "                        \n",
    "                        words.append({\n",
    "                            'text': word['value'],\n",
    "                            'coords': {\n",
    "                                'y1': float(y1),\n",
    "                                'y2': float(y2),\n",
    "                                'x1': float(x1),\n",
    "                                'x2': float(x2)\n",
    "                            }\n",
    "                        })\n",
    "        \n",
    "        # Sort words by y-coordinate first\n",
    "        words.sort(key=lambda x: x['coords']['y1'])\n",
    "        \n",
    "        # Group words that are on the same line\n",
    "        lines = []\n",
    "        current_line = [words[0]] if words else []\n",
    "        \n",
    "        for word in words[1:]:\n",
    "            last_word = current_line[-1] if current_line else None\n",
    "            \n",
    "            if last_word and self._is_same_line(last_word['coords'], word['coords']):\n",
    "                current_line.append(word)\n",
    "            else:\n",
    "                if current_line:\n",
    "                    # Sort words in the line by x-coordinate before adding to lines\n",
    "                    current_line.sort(key=lambda x: x['coords']['x1'])\n",
    "                    lines.append(current_line)\n",
    "                current_line = [word]\n",
    "        \n",
    "        if current_line:\n",
    "            # Sort the last line by x-coordinate\n",
    "            current_line.sort(key=lambda x: x['coords']['x1'])\n",
    "            lines.append(current_line)\n",
    "        \n",
    "        # Convert grouped words to text\n",
    "        formatted_text = []\n",
    "        for line in lines:\n",
    "            line_text = ' '.join(word['text'] for word in line)\n",
    "            formatted_text.append(line_text)\n",
    "        \n",
    "        return formatted_text\n",
    "    \n",
    "    def _is_same_line(self, coords1, coords2, tolerance_factor=0.5):\n",
    "        \"\"\"\n",
    "        Check if two words are on the same line based on vertical coordinates\n",
    "        Using a tolerance factor relative to text height\n",
    "        \"\"\"\n",
    "        height1 = coords1['y2'] - coords1['y1']\n",
    "        height2 = coords2['y2'] - coords2['y1']\n",
    "        avg_height = (height1 + height2) / 2\n",
    "        \n",
    "        mid1 = (coords1['y1'] + coords1['y2']) / 2\n",
    "        mid2 = (coords2['y1'] + coords2['y2']) / 2\n",
    "        \n",
    "        return abs(mid1 - mid2) < (avg_height * tolerance_factor)\n",
    "\n",
    "# Example usage\n",
    "def process_id_card(ocr_result):\n",
    "    processor = OCRTextProcessor()\n",
    "    formatted_text = processor.process_ocr_result(ocr_result)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEntityExtractor:\n",
    "    def __init__(self):\n",
    "        # Define fields with their keywords and tolerance levels\n",
    "        self.fields = [\n",
    "            {'name': 'provinsi', 'keywords': ['provinsi'], 'tolerance': 2},\n",
    "            {'name': 'kabupaten', 'keywords': ['kabupaten', 'kota'], 'tolerance': 2},\n",
    "            {'name': 'nik', 'keywords': ['nik'], 'tolerance': 1},\n",
    "            {'name': 'nama', 'keywords': ['nama'], 'tolerance': 1},\n",
    "            {'name': 'tempat_tgl_lahir', 'keywords': ['tempat/tgl', 'tempat/tgilahir', 'tempat','tompat/tgllah'], 'tolerance': 3},\n",
    "            # {'name': 'tanggal_lahir', 'keywords': ['tgl', 'tanggal'], 'tolerance': 2},\n",
    "            {'name': 'jenis_kelamin', 'keywords': ['jenis kelamin', 'kelamin'], 'tolerance': 2},\n",
    "            {'name': 'alamat', 'keywords': ['alamat'], 'tolerance': 2},\n",
    "            {'name': 'rt_rw', 'keywords': ['rt/rw', 'rtrw'], 'tolerance': 2},\n",
    "            {'name': 'kel_desa', 'keywords': ['kel/desa', 'kelurahan', 'desa'], 'tolerance': 2},\n",
    "            {'name': 'kecamatan', 'keywords': ['kecamatan', 'kec'], 'tolerance': 3},\n",
    "            {'name': 'agama', 'keywords': ['agama'], 'tolerance': 2},\n",
    "            {'name': 'status_perkawinan', 'keywords': ['status perkawinan', 'perkawinan'], 'tolerance': 3},\n",
    "            {'name': 'pekerjaan', 'keywords': ['pekerjaan', 'kerja'], 'tolerance': 3},\n",
    "            {'name': 'kewarganegaraan', 'keywords': ['kewarganegaraan'], 'tolerance': 4},\n",
    "            {'name': 'berlaku_hingga', 'keywords': ['berlaku hingga', 'hingga'], 'tolerance': 3}\n",
    "        ]\n",
    "\n",
    "    def levenshtein_distance(self, s1, s2):\n",
    "        \"\"\"Calculate the Levenshtein distance between two strings\"\"\"\n",
    "        if len(s1) < len(s2):\n",
    "            return self.levenshtein_distance(s2, s1)\n",
    "\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "\n",
    "        previous_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "\n",
    "        return previous_row[-1]\n",
    "\n",
    "    def find_field_match(self, line):\n",
    "        \"\"\"Find matching field for a line based on Levenshtein distance\"\"\"\n",
    "        words = line.lower().split()\n",
    "        if not words:\n",
    "            return None\n",
    "\n",
    "        best_match = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for field in self.fields:\n",
    "            for keyword in field['keywords']:\n",
    "                keyword_parts = keyword.lower().split()\n",
    "                \n",
    "                # Try matching with first word(s) of line\n",
    "                for i in range(min(len(words), len(keyword_parts) + 1)):\n",
    "                    line_part = ' '.join(words[:i+1])\n",
    "                    distance = self.levenshtein_distance(line_part, keyword)\n",
    "                    \n",
    "                    if distance < min_distance and distance <= field['tolerance']:\n",
    "                        min_distance = distance\n",
    "                        best_match = field\n",
    "\n",
    "        return best_match\n",
    "\n",
    "    def extract_value(self, line, field):\n",
    "        \"\"\"Extract value from a line based on field type\"\"\"\n",
    "        # Split line into parts\n",
    "        parts = line.split()\n",
    "        \n",
    "        # Find where the field name ends\n",
    "        field_end = 0\n",
    "        for i, part in enumerate(parts):\n",
    "            for keyword in field['keywords']:\n",
    "                if self.levenshtein_distance(part.lower(), keyword.lower()) <= field['tolerance']:\n",
    "                    field_end = i + 1\n",
    "                    break\n",
    "        \n",
    "        # Extract value portion\n",
    "        value = ' '.join(parts[field_end:]).strip()\n",
    "        \n",
    "        # Clean up common artifacts\n",
    "        value = value.replace(':', '').strip()\n",
    "        \n",
    "        return value if value else None\n",
    "\n",
    "    def extract_entities(self, lines):\n",
    "        \"\"\"Extract entities from list of lines\"\"\"\n",
    "        entities = {}\n",
    "        \n",
    "        for line in lines:\n",
    "            # Skip empty lines\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            \n",
    "            # Find matching field\n",
    "            field = self.find_field_match(line)\n",
    "            if field:\n",
    "                value = self.extract_value(line, field)\n",
    "                if value:\n",
    "                    # Special handling for fields that might have multiple parts\n",
    "                    if field['name'] in entities:\n",
    "                        if isinstance(entities[field['name']], list):\n",
    "                            entities[field['name']].append(value)\n",
    "                        else:\n",
    "                            entities[field['name']] = [entities[field['name']], value]\n",
    "                    else:\n",
    "                        entities[field['name']] = value\n",
    "\n",
    "        return entities\n",
    "\n",
    "# Example usage\n",
    "def extract_id_card_info(lines):\n",
    "    extractor = TextEntityExtractor()\n",
    "    return extractor.extract_entities(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROVINSI SULAWESI SELATAN',\n",
       " 'KABUPATEN MAROS',\n",
       " 'NIK 7301032705130004',\n",
       " 'NAMA MUH DHIAUR RAHMAN',\n",
       " 'TAMPAT/TGL LAHIR MAROS, 27-05 1993',\n",
       " 'JENIS KELAMIN LAK-LAKI GOL: DARAH:B',\n",
       " 'ALAMAT PP DARUL ISTIQAMAH',\n",
       " 'RT/RW 001/002',\n",
       " 'KEL/DESA BONTOA',\n",
       " 'KECAMATAN MANDAI',\n",
       " 'AGAMA ISLAM',\n",
       " 'STATUS PERKAWINAN: BELUM KAWIN',\n",
       " 'PEKERJAAN PELAJAPMAHASISWA',\n",
       " 'MAROS',\n",
       " 'KEWARGANEGERAAN WNI',\n",
       " '17-10-2017',\n",
       " 'BERLAKU HINGGA SEUMUR HIDUP']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the processor\n",
    "processor = OCRTextProcessor()\n",
    "formatted_text = processor.process_ocr_result(export)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to uppercase\n",
    "    text = text.upper()\n",
    "    # Remove single characters\n",
    "    text = ' '.join(word for word in text.split() if len(word) > 1)\n",
    "    # Remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to each string in the list\n",
    "processed_data = [preprocess_text(item) for item in formatted_text]\n",
    "processed_data = [item for item in processed_data if item]\n",
    "\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'provinsi': 'SULAWESI SELATAN',\n",
       " 'kabupaten': 'MAROS',\n",
       " 'nik': '7301032705130004',\n",
       " 'nama': 'MUH DHIAUR RAHMAN',\n",
       " 'tempat_tgl_lahir': 'LAHIR MAROS, 27-05 1993',\n",
       " 'jenis_kelamin': 'LAKI-LAKI',\n",
       " 'alamat': 'PP DARUL ISTIQAMAH',\n",
       " 'rt_rw': '001/002',\n",
       " 'kel_desa': 'BONTOA',\n",
       " 'kecamatan': 'MANDAI',\n",
       " 'agama': 'ISLAM',\n",
       " 'status_perkawinan': 'BELUM KAWIN',\n",
       " 'pekerjaan': 'PELAJAR/MAHASISWA',\n",
       " 'kewarganegaraan': 'WNI',\n",
       " 'berlaku_hingga': 'SEUMUR HIDUP'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = extract_id_card_info(processed_data)\n",
    "def post_processing(data):\n",
    "    import re\n",
    "\n",
    "    # Helper function to count matching characters\n",
    "    def count_matching_chars(a, char):\n",
    "        count = 0\n",
    "        for c in char:\n",
    "            if c in a:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def correct_agama(agama):\n",
    "        target_words = [\"ISLAM\", \"KRISTEN\", \"KATOLIK\", \"HINDU\", \"BUDDHA\", \"KONGHUCU\"]\n",
    "        agama = agama.lower()\n",
    "        match_scores = {word: count_matching_chars(agama, word.lower()) for word in target_words}\n",
    "        most_likely_agama = max(match_scores, key=match_scores.get)\n",
    "        return most_likely_agama\n",
    "    \n",
    "    def correct_jenis_kelamin(jenis_kelamin):\n",
    "        target_words = [\"LAKI-LAKI\", \"PEREMPUAN\"]\n",
    "        jenis_kelamin = jenis_kelamin.lower()\n",
    "        match_scores = {word: count_matching_chars(jenis_kelamin, word.lower()) for word in target_words}\n",
    "        most_likely_jenis_kelamin = max(match_scores, key=match_scores.get)\n",
    "        return most_likely_jenis_kelamin\n",
    "    \n",
    "    def correct_status_perkawinan(status_perkawinan):\n",
    "        target_words = [\"KAWIN\", \"BELUM KAWIN\", \"CERAI HIDUP\", \"CERAI MATI\"]\n",
    "        status_perkawinan = status_perkawinan.lower()\n",
    "        match_scores = {word: count_matching_chars(status_perkawinan, word.lower()) for word in target_words}\n",
    "        most_likely_status_perkawinan = max(match_scores, key=match_scores.get)\n",
    "        return most_likely_status_perkawinan\n",
    "    \n",
    "    def correct_pekerjaan(pekerjaan):\n",
    "        target_words = [\n",
    "            \"BELUM/TIDAK BEKERJA\", \"MENGURUS RUMAH TANGGA\", \"PELAJAR/MAHASISWA\", \"PENSIUNAN\",\n",
    "            \"PEGAWAI NEGERI SIPIL\", \"TENTARA NASIONAL INDONESIA\", \"KEPOLISIAN RI\", \"PERDAGANGAN\",\n",
    "            \"PETANI/PEKEBUN\", \"PETERNAK\", \"NELAYAN/PERIKANAN\", \"INDUSTRI\", \"KONSTRUKSI\", \"TRANSPORTASI\",\n",
    "            \"KARYAWAN SWASTA\", \"KARYAWAN BUMN\", \"KARYAWAN BUMD\", \"KARYAWAN HONORER\", \"BURUH HARIAN LEPAS\",\n",
    "            \"BURUH TANI/PERKEBUNAN\", \"BURUH NELAYAN/PERIKANAN\", \"BURUH PETERNAKAN\", \"PEMBANTU RUMAH TANGGA\",\n",
    "            \"TUKANG CUKUR\", \"TUKANG LISTRIK\", \"TUKANG BATU\", \"TUKANG KAYU\", \"TUKANG SOL SEPATU\",\n",
    "            \"TUKANG LAS/PANDAI BESI\", \"TUKANG JAHIT\", \"TUKANG GIGI\", \"PENATA RIAS\", \"PENATA BUSANA\",\n",
    "            \"PENATA RAMBUT\", \"MEKANIK\", \"SENIMAN\", \"TABIB\", \"PARAJI\", \"PERANCANG BUSANA\", \"PENTERJEMAH\",\n",
    "            \"IMAM MASJID\", \"PENDETA\", \"PASTOR\", \"WARTAWAN\", \"USTADZ/MUBALIGH\", \"JURU MASAK\", \"PROMOTOR ACARA\",\n",
    "            \"ANGGOTA DPR-RI\", \"ANGGOTA DPD\", \"ANGGOTA BPK\", \"PRESIDEN\", \"WAKIL PRESIDEN\",\n",
    "            \"ANGGOTA MAHKAMAH KONSTITUSI\", \"ANGGOTA KABINET/KEMENTERIAN\", \"DUTA BESAR\", \"GUBERNUR\",\n",
    "            \"WAKIL GUBERNUR\", \"BUPATI\", \"WAKIL BUPATI\", \"WALIKOTA\", \"WAKIL WALIKOTA\", \"ANGGOTA DPRD PROVINSI\",\n",
    "            \"ANGGOTA DPRD KABUPATEN/KOTA\", \"DOSEN\", \"GURU\", \"PILOT\", \"PENGACARA\", \"NOTARIS\", \"ARSITEK\",\n",
    "            \"AKUNTAN\", \"KONSULTAN\", \"DOKTER\", \"BIDAN\", \"PERAWAT\", \"APOTEKER\", \"PSIKIATER/PSIKOLOG\",\n",
    "            \"PENYIAR TELEVISI\", \"PENYIAR RADIO\", \"PELAUT\", \"PENELITI\", \"SOPIR\", \"PIALANG\", \"PARANORMAL\",\n",
    "            \"PEDAGANG\", \"PERANGKAT DESA\", \"KEPALA DESA\", \"BIARAWATI\", \"WIRASWASTA\"\n",
    "        ]\n",
    "        pekerjaan = pekerjaan.upper()\n",
    "        match_scores = {word: count_matching_chars(pekerjaan, word) for word in target_words}\n",
    "        most_likely_pekerjaan = max(match_scores, key=match_scores.get)\n",
    "        return most_likely_pekerjaan\n",
    "\n",
    "    data['jenis_kelamin'] = correct_jenis_kelamin(data['jenis_kelamin'])\n",
    "    data['agama'] = correct_agama(data['agama'])\n",
    "    data['pekerjaan'] = correct_pekerjaan(data['pekerjaan'])\n",
    "    data['status_perkawinan'] = correct_status_perkawinan(data['status_perkawinan'])\n",
    "    return data\n",
    "\n",
    "result = post_processing(entities)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"widi\"\n",
    "char = \"wd\"\n",
    "\n",
    "# count how many same characters founded are in the string\n",
    "count = 0\n",
    "for i in range(len(char)):\n",
    "    if char[i] in a:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the result:\n",
    "# provinsi: JAWA TENGAH kabupaten: . PURBALINGGA nik: - 330315040458000 nama: IFTAH SADJAD AHMADI tempat_lahir: PURBAUNGGA tanggal_lahir: 04-06-1998 jenis_kelamin: LAKRAKE Gol Darah a alamat: PERLMEDMIPAOAMMAGNFS rt_rw: 001003 kel_desa: BOJANEGARA kecamatan: PADAMARA agama: ISLAM status_perkawinan: BELUMKAWIN PUHBALINGGA pekerjaan: PELLARMAHASISHA 19092015 kewarganegaraan: WNI berlaku_hingga: SEUMUR RIDUP\n",
    "\n",
    "# do validation like:\n",
    "# 1. there is no number in \"pekerjaan\", so if there is detected number, remove the number\n",
    "# 2. in status perkawinan mostly the value is : belum kawin, kawin, cerai mati, cerai hidup. check if tolerance in that value. in my case it detected BELUMKAWIN PUHBALINGGA. remove else the value i gave you earlier (PUHBALINGGA)\n",
    "# 3. Gol darah is completly new key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ck-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
